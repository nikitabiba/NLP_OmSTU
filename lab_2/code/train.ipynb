{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e367b3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from navec import Navec\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from TextDataset import TextDataset\n",
    "from lib import tokenizer, vocab, vectorize_batch\n",
    "from models.RNN import RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9cd3f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "N = 25000\n",
    "batch_size = 128\n",
    "vocab_length = 500002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5bff56c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "navec = Navec.load(\"../models/navec_hudlit_v1_12B_500K_300d_100q.tar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c521bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, test_dataset  = TextDataset('../data/data.csv', N, 0.8, \"head\"), TextDataset('../data/data.csv', N, 0.2, \"tail\")\n",
    "train_dataset, val_dataset = random_split(train_dataset, [0.8, 0.2])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, collate_fn=vectorize_batch, shuffle=True)\n",
    "test_loader  = DataLoader(test_dataset, batch_size=batch_size, collate_fn=vectorize_batch)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, collate_fn=vectorize_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb035e26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 50]) torch.Size([128])\n"
     ]
    }
   ],
   "source": [
    "for X, Y in train_loader:\n",
    "    print(X.shape, Y.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f2f1d4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn = RNN().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "231403fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer : Embedding(500002, 300)\n",
      "Parameters : \n",
      "torch.Size([500002, 300])\n",
      "\n",
      "Layer : RNN(300, 20, batch_first=True)\n",
      "Parameters : \n",
      "torch.Size([20, 300])\n",
      "torch.Size([20, 20])\n",
      "torch.Size([20])\n",
      "torch.Size([20])\n",
      "\n",
      "Layer : Linear(in_features=20, out_features=15, bias=True)\n",
      "Parameters : \n",
      "torch.Size([15, 20])\n",
      "torch.Size([15])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for layer in rnn.children():\n",
    "    print(\"Layer : {}\".format(layer))\n",
    "    print(\"Parameters : \")\n",
    "    for param in layer.parameters():\n",
    "        print(param.shape)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a90fd85",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "loss_model = nn.CrossEntropyLoss()\n",
    "opt = torch.optim.Adam(rnn.parameters(), lr=0.001)\n",
    "\n",
    "lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(opt,\n",
    "                                                          mode='min',\n",
    "                                                          factor=0.1,\n",
    "                                                          patience=7,\n",
    "                                                          threshold=1e-4,\n",
    "                                                          threshold_mode='rel',\n",
    "                                                          cooldown=3,\n",
    "                                                          min_lr=0,\n",
    "                                                          eps=1e-8,\n",
    "                                                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec752d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5;   loss=2.9640:   1%|          | 1/125 [00:05<11:44,  5.68s/it]"
     ]
    }
   ],
   "source": [
    "EPOCHS = 5\n",
    "train_loss, train_acc, val_loss, val_acc = [], [], [], []\n",
    "train_precision, train_recall, train_f1 = [], [], []\n",
    "val_precision, val_recall, val_f1 = [], [], []\n",
    "list_ = []\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    rnn.train()\n",
    "    running_train_loss = []\n",
    "    all_train_preds, all_train_targets = [], []\n",
    "    train_loop = tqdm(train_loader, leave=False)\n",
    "\n",
    "    for x, targets in train_loop:\n",
    "        x = x.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        pred = rnn(x)\n",
    "        loss = loss_model(pred, targets)\n",
    "\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "        running_train_loss.append(loss.item())\n",
    "\n",
    "        preds = pred.argmax(dim=1)\n",
    "        all_train_preds.extend(preds.cpu().numpy())\n",
    "        all_train_targets.extend(targets.cpu().numpy())\n",
    "\n",
    "        train_loop.set_description(\n",
    "            f\"Epoch {epoch + 1}/{EPOCHS};   loss={np.mean(running_train_loss):.4f}\"\n",
    "        )\n",
    "\n",
    "    mean_train_loss = np.mean(running_train_loss)\n",
    "    acc_train = np.mean(np.array(all_train_preds) == np.array(all_train_targets))\n",
    "    prec_train = precision_score(all_train_targets, all_train_preds, average=\"weighted\")\n",
    "    rec_train = recall_score(all_train_targets, all_train_preds, average=\"weighted\")\n",
    "    f1_train = f1_score(all_train_targets, all_train_preds, average=\"weighted\")\n",
    "\n",
    "    train_loss.append(mean_train_loss)\n",
    "    train_acc.append(acc_train)\n",
    "    train_precision.append(prec_train)\n",
    "    train_recall.append(rec_train)\n",
    "    train_f1.append(f1_train)\n",
    "\n",
    "    rnn.eval()\n",
    "    with torch.no_grad():\n",
    "        running_val_loss = []\n",
    "        all_val_preds, all_val_targets = [], []\n",
    "        for x, targets in val_loader:\n",
    "            x = x.to(device)\n",
    "            targets = targets.to(device)\n",
    "\n",
    "            pred = rnn(x)\n",
    "            loss = loss_model(pred, targets)\n",
    "\n",
    "            running_val_loss.append(loss.item())\n",
    "\n",
    "            preds = pred.argmax(dim=1)\n",
    "            all_val_preds.extend(preds.cpu().numpy())\n",
    "            all_val_targets.extend(targets.cpu().numpy())\n",
    "\n",
    "        mean_val_loss = np.mean(running_val_loss)\n",
    "        acc_val = np.mean(np.array(all_val_preds) == np.array(all_val_targets))\n",
    "        prec_val = precision_score(all_val_targets, all_val_preds, average=\"weighted\", zero_division=0)\n",
    "        rec_val = recall_score(all_val_targets, all_val_preds, average=\"weighted\", zero_division=0)\n",
    "        f1_val = f1_score(all_val_targets, all_val_preds, average=\"weighted\", zero_division=0)\n",
    "\n",
    "        lr_scheduler.step(metrics=mean_val_loss)\n",
    "        lr = lr_scheduler.get_last_lr()\n",
    "        list_.append(lr)\n",
    "\n",
    "        val_loss.append(mean_val_loss)\n",
    "        val_acc.append(acc_val)\n",
    "        val_precision.append(prec_val)\n",
    "        val_recall.append(rec_val)\n",
    "        val_f1.append(f1_val)\n",
    "\n",
    "    print(\n",
    "        f\"Epoch {epoch+1}/{EPOCHS}; \"\n",
    "        f\"train_loss={mean_train_loss:.4f}; train_acc={acc_train:.4f}; \"\n",
    "        f\"train_prec={prec_train:.4f}; train_rec={rec_train:.4f}; train_f1={f1_train:.4f}; \"\n",
    "        f\"val_loss={mean_val_loss:.4f}; val_acc={acc_val:.4f}; \"\n",
    "        f\"val_prec={prec_val:.4f}; val_rec={rec_val:.4f}; val_f1={f1_val:.4f}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cba9bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn.eval()\n",
    "with torch.no_grad():\n",
    "    running_test_loss = []\n",
    "    all_test_preds, all_test_targets = [], []\n",
    "    for x, targets in test_loader:\n",
    "        x = x.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        pred = rnn(x)\n",
    "        loss = loss_model(pred, targets)\n",
    "\n",
    "        running_test_loss.append(loss.item())\n",
    "\n",
    "        preds = pred.argmax(dim=1)\n",
    "        all_test_preds.extend(preds.cpu().numpy())\n",
    "        all_test_targets.extend(targets.cpu().numpy())\n",
    "\n",
    "    mean_test_loss = np.mean(running_test_loss)\n",
    "    acc_test = np.mean(np.array(all_test_preds) == np.array(all_test_targets))\n",
    "    prec_test = precision_score(all_test_targets, all_test_preds, average=\"weighted\")\n",
    "    rec_test = recall_score(all_test_targets, all_test_preds, average=\"weighted\")\n",
    "    f1_test = f1_score(all_test_targets, all_test_preds, average=\"weighted\")\n",
    "\n",
    "print(\n",
    "    f\"test_loss={mean_test_loss:.4f}; test_acc={acc_test:.4f}; \"\n",
    "    f\"test_prec={prec_test:.4f}; test_rec={rec_test:.4f}; test_f1={f1_test:.4f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "219bd837",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_loss)\n",
    "plt.plot(val_loss)\n",
    "plt.legend(['train', 'val'])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
