{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76031434",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from lib.Transformer import Transformer\n",
    "from lib.TextDataset import TextDataset\n",
    "from transformers import PreTrainedTokenizerFast\n",
    "from torch.utils.data import DataLoader\n",
    "from lib.lib import load_dataset, collate_fn, generate_story_end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6930af47",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0ffc442",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 0.0003\n",
    "EPOCHS = 40\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "53ae138e",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 60000\n",
    "d_model = 512\n",
    "n_heads = 8\n",
    "d_ff = 2048\n",
    "n_encoder_layers=4\n",
    "n_decoder_layers=6\n",
    "max_len = 1000\n",
    "pad_idx = 0\n",
    "dropout = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c752a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = PreTrainedTokenizerFast(\n",
    "    tokenizer_file=\"../models/bpe_tokenizer/tokenizer.json\",\n",
    "    bos_token=\"<s>\",\n",
    "    eos_token=\"</s>\",\n",
    "    unk_token=\"<unk>\",\n",
    "    pad_token=\"<pad>\",\n",
    "    additional_special_tokens=[\"<|endoftext|>\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2611908f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = load_dataset(\"../data/train.txt\", tokenizer, data_fraction=N)\n",
    "test_data  = load_dataset(\"../data/test.txt\", tokenizer, data_fraction=N)\n",
    "\n",
    "pad_id = tokenizer.pad_token_id\n",
    "train_loader = DataLoader(TextDataset(train_data), batch_size=batch_size, shuffle=True, collate_fn=lambda x: collate_fn(x, pad_id, max_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3c1d0a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = Transformer(vocab_size=vocab_size, d_model=d_model, n_heads=n_heads, d_ff=d_ff, n_encoder_layers=n_encoder_layers, n_decoder_layers=n_decoder_layers, max_len=max_len, pad_idx=pad_idx, dropout=dropout).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2ca07ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(transformer.parameters(), lr=3e-4)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=pad_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "80245934",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: loss = 8.3663\n",
      "Epoch 2: loss = 6.1787\n",
      "Epoch 3: loss = 5.7563\n",
      "Epoch 4: loss = 5.2607\n",
      "Epoch 5: loss = 4.8377\n",
      "Epoch 6: loss = 4.5219\n",
      "Epoch 7: loss = 4.2633\n",
      "Epoch 8: loss = 4.0510\n",
      "Epoch 9: loss = 3.8653\n",
      "Epoch 10: loss = 3.6871\n",
      "Epoch 11: loss = 3.5092\n",
      "Epoch 12: loss = 3.3446\n",
      "Epoch 13: loss = 3.1824\n",
      "Epoch 14: loss = 3.0175\n",
      "Epoch 15: loss = 2.8543\n",
      "Epoch 16: loss = 2.6904\n",
      "Epoch 17: loss = 2.5345\n",
      "Epoch 18: loss = 2.3772\n",
      "Epoch 19: loss = 2.2207\n",
      "Epoch 20: loss = 2.0578\n",
      "Epoch 21: loss = 1.9179\n",
      "Epoch 22: loss = 1.7683\n",
      "Epoch 23: loss = 1.6297\n",
      "Epoch 24: loss = 1.4905\n",
      "Epoch 25: loss = 1.3649\n",
      "Epoch 26: loss = 1.2508\n",
      "Epoch 27: loss = 1.1394\n",
      "Epoch 28: loss = 1.0442\n",
      "Epoch 29: loss = 0.9531\n",
      "Epoch 30: loss = 0.8691\n",
      "Epoch 31: loss = 0.7987\n",
      "Epoch 32: loss = 0.7258\n",
      "Epoch 33: loss = 0.6578\n",
      "Epoch 34: loss = 0.6020\n",
      "Epoch 35: loss = 0.5512\n",
      "Epoch 36: loss = 0.5139\n",
      "Epoch 37: loss = 0.4818\n",
      "Epoch 38: loss = 0.4526\n",
      "Epoch 39: loss = 0.4251\n",
      "Epoch 40: loss = 0.3996\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    transformer.train()\n",
    "    total_loss = 0\n",
    "    for src, tgt in train_loader:\n",
    "        src, tgt = src.to(device), tgt.to(device)\n",
    "\n",
    "        logits = transformer(src, tgt[:, :-1])\n",
    "        loss = criterion(logits.reshape(-1, logits.size(-1)), tgt[:, 1:].reshape(-1))\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}: loss = {total_loss / len(train_loader):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fc8edde5",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = \"../models/transformer/checkpoints/transformer_tinystories.pt\"\n",
    "torch.save({\n",
    "    \"model_state_dict\": transformer.state_dict(),\n",
    "    \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "    \"epoch\": epoch + 1,\n",
    "    \"loss\": total_loss / len(train_loader),\n",
    "    \"config\": {\n",
    "        \"vocab_size\": transformer.output_linear.out_features,\n",
    "        \"d_model\": transformer.d_model,\n",
    "        \"pad_idx\": transformer.pad_idx,\n",
    "    }\n",
    "}, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "973ed87f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = torch.load(\"../models/transformer/checkpoints/transformer_tinystories.pt\", map_location=device)\n",
    "\n",
    "transformer = Transformer(\n",
    "    vocab_size=checkpoint[\"config\"][\"vocab_size\"],\n",
    "    d_model=checkpoint[\"config\"][\"d_model\"],\n",
    "    n_heads=n_heads,\n",
    "    d_ff=d_ff,\n",
    "    n_encoder_layers=n_encoder_layers,\n",
    "    n_decoder_layers=n_decoder_layers,\n",
    "    max_len=max_len,\n",
    "    pad_idx=checkpoint[\"config\"][\"pad_idx\"],\n",
    "    dropout=dropout\n",
    ").to(device)\n",
    "\n",
    "transformer.load_state_dict(checkpoint[\"model_state_dict\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "21f0bc8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " around, they found a big pond. The boy was so happy that he had lots of fun. He showed him to stay and make sure he would take care of fun. The moral of the story is to stay connected. Together they both with the story is to stay and get more. When the story is to go home, the story is to stay connected. He thanked the story is to stay and even more and even more careful. Together they both with their cool and even more careful when they were safe and even more. From then on, the best birthday ever after. The moral of friends for helping me, the story is to always very happy and even more. Every week, the story is to always listen to explore together until they were very proud of friends. They had made sure that being different things in the story is to explore together until they both with their moms and even more. When they learned that being different things in the story is to explore together again. And the story is\n"
     ]
    }
   ],
   "source": [
    "print(generate_story_end(transformer, tokenizer, \"I was walking with my friend\", device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "65d379da-ca1c-4566-84b9-0d565dc2dc21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " began to follow the friends. The rocket felt happy and smooth the cloth. She watched the rocket was so happy. The rocket thanked the rocket and gave it a big hug. Finally the rocket was time to go home. The little girl's friends. She knew that she had been creative enough to go home. They would always visit the moon. And the moon for the moon for hours and smiled and hugged the rocket was sure to share. And the cloth. And the rocket was always visit the rocket was always visit the rocket and smiled as a wonderful time to share for hours and thanked the moon. The end. It was always visit the rocket and smiled as a wonderful time to share. It was always visit the rocket and smiled at her journey and said goodbye to have good day. It was always visit the wonderful time to have good day. The old man for the wonderful time to have never forget it was always visit the wonderful time to have never forget it was always visit. The old man.\n"
     ]
    }
   ],
   "source": [
    "print(generate_story_end(transformer, tokenizer, \"Once upon a time, there was a graceful cat named Kitty. She loved to play with her ball and jump around the house. Kitty was very happy and liked to make her friends laugh. One day, Kitty saw a tap in the garden.\", device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f0b8b957-c5ba-4ea0-9bca-18cc419e791b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " began to the sky. The girl felt frustrated. She watched as she could get closer. As she heard a big, the peopleâ€™s house. The little girl was so happy. She gave the tree was so proud that she had a big hug and said. And the best of friends. And from then on, the park, and were happy and went on, the little girl had a big hug. And the best of friends. And the park was happy and joy, she would come back. And the park was happy and were happy and were happy again. And the park was happy and were happy again. And the best of friends had a wonderful adventure. And the best day on, she would always visit to have lots of friends. And the best day on, she would always visit to have lots of friends. And the most beautiful and share. And the best of friends. And the best of friends. And the most beautiful and share and share and share. And the best day\n"
     ]
    }
   ],
   "source": [
    "print(generate_story_end(transformer, tokenizer, \"Once upon a time, there was a naughty bee named Buzzy. Buzzy loved to fly around the big tree and play with the other bees. One day, Buzzy saw a little girl named Lucy sitting on the grass. Buzzy flew down and said\", device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa83e8d-ab7d-499e-aeef-dd148c71db21",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
